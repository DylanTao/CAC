{
    "id": "genai_autism",
    "title": "Examining sentiment towards AI-based assistive technologies for people with Autism",
    "content": "Content is too long and is chunked into 2 child nodes.",
    "summary": "This document explores the potential of AI-based assistive solutions for people with Autism and specifically addresses Nvidia's new video conferencing feature. A qualitative coding of 162 comments discussing the technology revealed negative responses towards the feature. These comments highlighted that eye contact is not always relevant in social interactions and can cause discomfort for individuals with Autism. The paper suggests developing generative AI-based assistive solutions and presents open questions that need to be investigated further in this space.",
    "children": [
        {
            "id": "genai_autism.chunk_1",
            "title": "Exploring outlooks towards generative AI-based assistive technologies for people with Autism",
            "content": "Exploring outlooks towards generative AI-based assistive technologies for people with Autism DEEPAK GIRI, Indiana University-Purdue University Indianapolis, United States ERIN BRADY, Indiana University-Purdue University Indianapolis, United States The last few years have significantly increased global interest in generative artificial intelligence. Deepfakes , which are synthetically created videos, emerged as an application of generative artificial intelligence. Fake news and pornographic content have been the two most prevalent negative use cases of deepfakes in the digital ecosystem. Deepfakes have some advantageous applications that experts in the subject have thought of in the areas of filmmaking, teaching, etc. Research on the potential of deepfakes among people with disabilities is, however, scarce or nonexistent. This workshop paper explores the potential of deepfakes as an assistive technology. We examined Reddit conversations regarding Nvdia\u2019s new videoconferencing feature which allows participants to maintain eye contact during online meetings. Through manual web scraping and qualitative coding, we found 162 relevant comments discussing the relevance and appropriateness of the technology for people with Autism. The themes identified from the qualitative codes indicate a number of concerns for technology among the autistic community. We suggest that developing generative AI-based assistive solutions will have ramifications for human-computer interaction (HCI), and present open questions that should be investigated further in this space. 1 INTRODUCTION Deepfakes are hyper-realistic content (commonly videos) created by generative artificial intelligence [ 24]. Traditionally, people have been manipulating videos through editing tools and these kinds of videos are called cheapfakes [ 19]. Though cheapfakes are easier to detect by anyone, deepfakes on the other hand are so novel in nature that it is harder to identify even with digital forensic techniques. People have come a long way in creating deep fakes since the introduction of Generative Adversarial Networks [ 7], as they now only need smaller training datasets to create convincing content. Although deepfake detection will not be covered in this work, researchers predict that it will eventually call for more robust and dynamic algorithms [9, 14]. Deepfakes are notoriously used to generate pornographic content and it makes literally anyone a potential target [ 8]. Deepfakes are not limited to producing personal harm, they can destabilize governments, economies and specific target groups [ 1,22,24]. While deepfake\u2019s bad applications are readily apparent, experts in the field and researchers are also seeing certain advantages of the technique. Deepfake has been successfully used by filmmakers to transform older actors into their youthful selves [ 4]. Artificially created characters can be used in Deepfake as a teaching tool to actively engage students in the classroom [ 5,11]. Moreover, deepfakes have been suggested as potential digital assistive technologies for individuals who have lost their vocal or facial expression due to an injury or illness [ 15]. Research on human perception [20,26], attitudes [ 19], and dialogues [ 6] about deepfake videos have previously been conducted. Studies investigating the perceptions and attitudes of people with disabilities toward prospective deepfake-based assistive technologies do not exist, though. One specific area where a new deepfake technology has been proposed as beneficial for disabled users is in making eye contact over video calls. Making direct eye contact with someone is a social behaviour which has emotional and communicative meaning [ 18]. Eye contact is recognized as an important social signal, indicating that the speaker intends to communicate with someone, and can lead to emotional responses which may influence how the speaker\u2019s message is interpreted [ 18]. However, people with autism have difficulty maintaining eye contact during conversations [17], to the point that \u201cabnormalities in eye contact\u201d are explicitly included as part of the DSM-5 diagnostic criteria for 12 Giri and Brady autism. For people with autism, prolonged eye contact feels invasive, and can elicit negative emotional and physiological responses or trigger sensory overload [21]. The introduction of the eye contact functionality by the semiconductor behemoth Nvidia in its conferencing software, broadcast v1.4, has sparked some discussion within the autistic community. This technology artificially modifies live video content to make it appear as if the person in the video frame is making direct eye contact with the viewer, even if in reality their eyes are focused elsewhere. While the company does not frame their eye contact technology as solely an assistive technology, they highlight this as a valuable application of the feature, mentioned in Nvidia Technical Blog (2023): \"Maintaining eye contact is also occasionally problematic for many physiological reasons. A lot of kids and adults find it difficult to establish and maintain eye contact. \u201d [2] Prior research within the HCI community has sought to improve eye contact behaviours specifically among people with autism, through interventions such as wearable glasses which track gaze and give feedback when the wearer is not maintaining eye contact [10], or eye tracking games which incentivize maintaining eye contact [13]. Other HCI work has critiqued these types of technologies for attempting to make autistic people conform to neurotypical conversational norms [ 25] and identified ways in which autistic people may try to \u201cmask\u201d their autism and appear neurotypical through behaviours like faking eye contact on a video call [ 27]. These masking behaviours require significant cognitive effort for autistic people, and autistic people appreciated that making direct eye contact is not a conversational norm on video conferencing tools [ 27]. It is unclear from this whether people with autism would find artificially generated \u201ceye contact\u201d beneficial, neutral, or harmful. In this study, we examined Reddit comments on posts related to Nvidia\u2019s technology to gain early insights into people\u2019s reactions to generative AI-based assistive technologies. The eye contact function from Nvidia was released in early January 2023, and since then 162 relevant comments have been gathered. We conducted qualitative coding to uncover the ideas behind the conversations and used these themes to identify open questions in the space of generative AI-based assistive technologies. 2 DATA AND FINDINGS We manually identified 9 Reddit discussion threads where users were discussing Nvidia\u2019s eye contact functionality in relation to Autism through a web search for relevant keywords (e.g., \u201cNvidia autism site: reddit.com\u201c). 5 of these discus- sions were in the /r/autism subreddit, and the others were from /r/AutisticAdults, /r/autismmemes, /r/nextfuckinglevel, and /r/nvidia. We collected all comments from the posts in autism-specific subreddits. For posts in other subreddits, we manually screened the comments and only collected the ones which explicitly discussed autism or neurodiversity. From these posts, we collected 162 comments. The lead researcher did an initial open coding pass on the comments. The researchers then met to discuss the codes and expand the codeset further. Data were then organized into high-level themes, described in detail below. Additionally, we recorded whether the commenters self-disclosed in their comments that: (a) they themselves had autism (20 commenters); (b) they did not have autism, but had close family members or friends with autism (4); or (c) they did not have autism (22). The other 116 comments did not include any disclosure of disability status. 2.1 Sentiment towards prospective generative AI assistive technologies A majority of comments (N=88) expressed negative responses towards Nvidia\u2019s eye contact feature. A large portion of Redditors angrily criticized the feature, describing it as \u201cnightmare fuel\u201d and indicated that they would choose not to use it at all. Many people criticized it as a \"masking strategy\" that wouldn\u2019t improve their real-world circumstances,Exploring outlooks towards generative AI-based assistive technologies for people with Autism 3 or questioned the value of eye contact for communication at all. Comments described concerns both about using the feature to alter their own videos, and about having to be on video calls with others using the feature. Despite these concerns, a considerable number of comments (N=46) were in support of the functionality. Autistic individuals described how the feature could be utilized to help them livestream effectively, confidently communicate with neurotypical individuals, and succeed in jobs which are communication-intensive like sales. Some users had even higher expectations for this technology, wondering if it could eventually be used for in-person encounters (e.g., \u201c Do they gave special glasses that made that in real life? I\u2019m autistic \u201d). Others sought some kind of control over the functionality. Neurotypical people made 14 of the 46 comments in favour of the feature because they thought it would make people on the spectrum more at ease during online encounters. In the comments about the feature\u2019s usefulness, 3 out of 46 Redditors mentioned relatives who had autism. Among the 46 comments where commenters self-disclosed whether they were neurotypical or autistic, there was much more disparity in the opinions of the commenters who were autistic (10 positive, 8 negative, 2 neutral/no opinion) than those of commenters who identified as neurotypical (14 positive, 4 negative, 4 neutral/no opinion). 2.2 Video conferencing behaviour and setup The comments revealed the video-conferencing behaviour of people with autism. People stated that turning off their cameras helps them with their social anxiety. Some commenters admitted their tendency of looking at themselves in the video conferencing software and anticipated that the functionality would increase this behaviour. The foundational idea of the eye contact functionality was criticized in one of the comments \" most individuals don\u2019t look at their camera since they\u2019re too busy staring at their screen. \" There have been questions about whether this feature will be useful to everyone depending on their workstation configuration. An individual quoted \u201c The device camera isn\u2019t in the same location as people\u2019s eyes, which results in nobody actually looking like they\u2019re looking at other people\u2019s eyes. \u201d Another comment mentioned that the eye contact feature would make things worse when people have a multiple monitor setup. The educator mentioned that eye movement helps their students know when they are referencing the slides in the second monitor. A game streamer questioned the usefulness of this feature in his line of work, as it would make things strange for him because it would appear to his audience as though he isn\u2019t paying attention to the game at all. 2.3 Relevance of eye contact During our analysis, we found out that a significant number of comments (N=50) expressed eye contact to be irrelevant in social interactions. As evidenced by an individual who claims to feel less apprehensive when interpreting facial expressions and tone of voice as opposed to direct eye contact. Some comments harshly criticized the need for eye contact and had a strong stance that generative AI should not normalize it. One comment quoted \u201c I don\u2019t want to be looking into the camera and I don\u2019t want software doing it for me either. It would feel like I\u2019m being forced to make eye contact against my will even if I\u2019m not physically doing so. \u201d Another set of comments questioned the societal aspirations of neurotypical individuals and felt the eye contact functionality was a personal attack on their social interaction preferences. Many comments advocated for a need of spreading awareness in society in the sense that it is completely normal to not make eye contact. One comment elaborated \u201c Basically, making other people less uncomfortable is the wrong message. Better is to normalize the idea that not everyone is \u201cnormal\u201d and that things like eye contact shouldn\u2019t be the social expectation or demand. That\u2019s my opinion anyway. Other people have differing opinions, but I really don\u2019t think conformity should be the goal. \u201d While most comments were direct disapproval of eye contact in social interaction, some comments looked at it through the perspective of culture and neurotypical individuals. One comment stated that the relevance4 Giri and Brady of eye contact would have stemmed from the societal belief that it is a sign of attentive listening and sincerity when speaking. While another comment mentioned the relevance of eye contact in certain cultures and is not necessary to be mimicked everywhere. 2.4 Interactions are creepy Commenters (N=35) felt the eye contact functionality to be creepy and disturbing. One comment quoted \u201c This would only make me look insane and murderous. \u201d Others also pointed out that the eye contact function was strange because social interactions don\u2019t typically",
            "summary": "This workshop paper explores the potential of generative AI-based assistive solutions for people with Autism, specifically in regards to Nvidia's new video conferencing feature that allows participants to maintain eye contact during online meetings. Researchers conducted qualitative coding on 162 relevant comments discussing the appropriateness of the technology and found that while a majority of commenters expressed negative responses towards the feature, there were some who supported it for livestreaming or communication-intensive jobs. The comments also revealed that eye contact is not always relevant in social interactions and can cause discomfort for individuals with Autism. The paper suggests developing generative AI-based assistive solutions will have ramifications for human-computer interaction (HCI), and presents open questions that should be investigated further in this space.",
            "children": []
        },
        {
            "id": "genai_autism.chunk_2",
            "title": "Sentiment towards Generative AI-based Assistive Technologies for Individuals with Autism",
            "content": "and neurotypical individuals. One comment stated that the relevance4 Giri and Brady of eye contact would have stemmed from the societal belief that it is a sign of attentive listening and sincerity when speaking. While another comment mentioned the relevance of eye contact in certain cultures and is not necessary to be mimicked everywhere. 2.4 Interactions are creepy Commenters (N=35) felt the eye contact functionality to be creepy and disturbing. One comment quoted \u201c This would only make me look insane and murderous. \u201d Others also pointed out that the eye contact function was strange because social interactions don\u2019t typically entail long stretches of eye contact; instead, it appears more like gazing. Those with autism noted that it was not only ineffective but would also increase people\u2019s lack of confidence in one another, which would have long-term effects on society. Many believed that the gaze intensity was one of the things that made eye contact unsettling. One commenter brought up the possibility of using technology in scripted media. Some also expressed privacy concerns since they thought using the software would make them feel watched over. 3 DISCUSSIONS This preliminary investigation qualitatively examined public sentiment towards generative AI-based assistive technolo- gies for people with autism. Our findings suggest that there are mixed opinions towards generative AI-based assistive technology among both autistic and neurotypical individuals. Although we observed a negative inclination towards the technology, there were also significant comments regarding its perceived usefulness, especially from neurotypical commenters. These findings give us an initial look at public sentiment towards the use of generative AI for assistive purposes, but need to be validated through interviews and contextual inquiry in future work. Below, we present some open questions raised by our analysis, which we hope to discuss with the other workshop attendees and continue to explore in future work. Usability of Generative AI-based Technologies: We came across various comments questioning the usability of generative AI-based assistive technology. The comments described how the technology would not embed well with their workstation setup, nature of work and behaviour. This calls for human factors research to better understand how autistic individuals would like to interact with generative AI-based assistive technologies and how their environment would support the same. Challenging Neurotypical Communication Norms: Many commenters pushed back against the ableist as- sumptions embedded into this style of generative AI systems, questioning the necessity of making eye contact during communication. Generative AI systems are trained on large datasets, but these datasets often represent the experiences of people without disabilities. Investigating Uncanniness: The unsettling and unnatural nature of this potential assistive technology based on generative AI was one of the key themes that came out of our work. The comments exemplified the technology\u2019s position in the uncanny valley, which is characterized by a nonlinear relationship between affinity and perceived human likeness [ 12]. Researchers have been attempting to comprehend this phenomenon with AI [ 3,23], and it gives us a direction to comprehend it specifically for assistive technologies based on generative AI to produce reliable interventions. Additionally, prior research in the accessibility domain indicates that people may react more positively to new technologies if they know they are being used for assistive purposes [ 16]; it would be useful to explore whether neurotypical people have more positive reactions to generative AI-based assistive technologies if they know why they are being used.Exploring outlooks towards generative AI-based assistive technologies for people with Autism 5 REFERENCES [1] Deepfake videos could \u2019spark\u2019 violent social unrest. BBC News (June 2019). [2] Improve Human Connection in Video Conferences with NVIDIA Maxine Eye Contact, Jan. 2023. [3]Avdeeff, M. Artificial Intelligence & Popular Music: SKYGGE, Flow Machines, and the Audio Uncanny Valley. Arts 8 , 4 (Dec. 2019), 130. Number: 4 Publisher: Multidisciplinary Digital Publishing Institute. [4]Baxter, J. How Star Wars Deepfake Seriously Improves Luke Skywalker Cameo in The Mandalorian | Den of Geek, 2021. [5]Edwards, C. Male professor turns himself into anime schoolgirl to teach students remotely during coronavirus lockdown | The US Sun, 2020. [6]Gamage, D., Ghasiya, P., Bonagiri, V., Whiting, M. E., and Sasahara, K. Are Deepfakes Concerning? Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Implications. In CHI Conference on Human Factors in Computing Systems (New Orleans LA USA, Apr. 2022), ACM, pp. 1\u201319. [7]Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. Generative Adversarial Networks, June 2014. arXiv:1406.2661 [cs, stat]. [8]Harwell, D. Fake-porn videos are being weaponized to harass and humiliate women: \u2019everybody is a potential target\u2019. Washington Post, 2018. [9]Harwell, D. Top AI researchers race to detect \u2018deepfake\u2019 videos: \u2018We are outgunned\u2019. Washington Post (Aug. 2019). [10] Kline, A., Voss, C., Washington, P., Haber, N., Schwartz, H., Tariq, Q., Winograd, T., Feinstein, C., and Wall, D. P. Superpower Glass. GetMobile: Mobile Computing and Communications 23 , 2 (Nov. 2019), 35\u201338. [11] Kosmyna, N., Gross, A., and Maes, P. \"The thinking cap 2.0\": preliminary study on fostering growth mindset of children by means of electroen- cephalography and perceived magic using artifacts from fictional sci-fi universes. In Proceedings of the Interaction Design and Children Conference (London United Kingdom, June 2020), ACM, pp. 458\u2013469. [12] Mori, M., MacDorman, K. F., and Kageki, N. The Uncanny Valley [From the Field]. IEEE Robotics & Automation Magazine 19 , 2 (June 2012), 98\u2013100. Conference Name: IEEE Robotics & Automation Magazine. [13] Ng, Y.-K., and Pera, M. S. Recommending social-interactive games for adults with autism spectrum disorders (ASD). In Proceedings of the 12th ACM Conference on Recommender Systems (New York, NY, USA, Sept. 2018), RecSys \u201918, Association for Computing Machinery, pp. 209\u2013213. [14] Passos, L. A., Jodas, D., da Costa, K. A. P., J\u00fanior, L. A. S., Colombo, D., and Papa, J. P. A Review of Deep Learning-based Approaches for Deepfake Content Detection, Feb. 2022. arXiv:2202.06095 [cs] version: 1. [15] Pataranutaporn, P., Danry, V., Leong, J., Punpongsanon, P., Novy, D., Maes, P., and Sra, M. AI-generated characters for supporting personalized learning and well-being. Nature Machine Intelligence 3 , 12 (Dec. 2021), 1013\u20131022. Number: 12 Publisher: Nature Publishing Group. [16] Profita, H., Albaghli, R., Findlater, L., Jaeger, P., and Kane, S. K. The at effect: how disability affects the perceived social acceptability of head-mounted display use. In proceedings of the 2016 CHI conference on human factors in computing systems (2016), pp. 4884\u20134895. [17] Senju, A., and Johnson, M. H. Atypical eye contact in autism: models, mechanisms and development. Neuroscience & Biobehavioral Reviews 33 , 8 (2009), 1204\u20131214. [18] Senju, A., and Johnson, M. H. The eye contact effect: mechanisms and development. Trends in Cognitive Sciences 13 , 3 (Mar. 2009), 127\u2013134. Publisher: Elsevier. [19] Shahid, F., Kamath, S., Sidotam, A., Jiang, V., Batino, A., and Vashistha, A. \u201dIt Matches My Worldview\u201d: Examining Perceptions and Attitudes Around Fake Videos. In CHI Conference on Human Factors in Computing Systems (New Orleans LA USA, Apr. 2022), no. 17, ACM, pp. 1\u201315. [20] Tahir, R., Batool, B., Jamshed, H., Jameel, M., Anwar, M., Ahmed, F., Zaffar, M. A., and Zaffar, M. F. Seeing is Believing: Exploring Perceptual Differences in DeepFake Videos. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama Japan, May 2021), ACM, pp. 1\u201316. [21] Trevisan, D. A., Roberts, N., Lin, C., and Birmingham, E. How do adults and teens with self-declared Autism Spectrum Disorder experience eye contact? A qualitative analysis of first-hand accounts. PLOS ONE 12 , 11 (Nov. 2017), e0188446. Publisher: Public Library of Science. [22] Vaccari, C., and Chadwick, A. Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News. Social Media + Society 6 , 1 (Jan. 2020), 2056305120903408. Publisher: SAGE Publications Ltd. [23] Weisman, W. D., and Pe\u00f1a, J. F. Face the Uncanny: The Effects of Doppelganger Talking Head Avatars on Affect-Based Trust Toward Artificial Intelligence Technology are Mediated by Uncanny Valley Perceptions. Cyberpsychology, Behavior, and Social Networking 24 , 3 (Mar. 2021), 182\u2013187. Publisher: Mary Ann Liebert, Inc., publishers. [24] Westerlund, M. The Emergence of Deepfake Technology: A Review. Technology Innovation Management Review 9 , 11 (Jan. 2019), 39\u201352. [25] Williams, R. M., and Gilbert, J. E. Perseverations of the academy: A survey of wearable technologies applied to autism intervention. International Journal of Human-Computer Studies 143 (Nov. 2020), 102485. [26] W\u00f6hler, L., Zembaty, M., Castillo, S., and Magnor, M. Towards Understanding Perceptual Differences between Genuine and Face-Swapped Videos. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (Yokohama Japan, May 2021), ACM, pp. 1\u201313. [27] Zolyomi, A., Begel, A., Waldern, J. F., Tang, J., Barnett, M., Cutrell, E., McDuff, D., Andrist, S., and Morris, M. R. Managing Stress: The Needs of Autistic Adults in Video Calling. Proceedings of the ACM on Human-Computer Interaction 3 , CSCW (Nov. 2019), 134:1\u2013134:29.",
            "summary": "This document examines sentiment towards generative AI-based assistive technologies for individuals with autism. While the technology was considered useful by some neurotypical individuals, there were mixed opinions and criticisms raised by both autistic and neurotypical commenters. Many felt that the gaze intensity of the eye contact feature made it unsettling and creepy. Additionally, some voiced privacy concerns and called for further research into the technology's usability, effectiveness, and social implications.",
            "children": []
        }
    ]
}